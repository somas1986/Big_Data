{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and define common helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastavro==1.5.1 in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastavro==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iteration_utilities in /opt/conda/lib/python3.10/site-packages (0.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install iteration_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: avro in /opt/conda/lib/python3.10/site-packages (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/assignment03_Vayuvegula_SomaShekar\n",
      "/home/jovyan/assignment03_Vayuvegula_SomaShekar/schemas\n",
      "/home/jovyan/assignment03_Vayuvegula_SomaShekar/results\n"
     ]
    }
   ],
   "source": [
    "from iteration_utilities import unique_everseen\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import avro.schema\n",
    "import fastavro\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "# from fs_s3fs import S3FS\n",
    "import pyarrow as pa\n",
    "from pyarrow.json import read_json\n",
    "import pyarrow.parquet as pq\n",
    "#import fastavro\n",
    "from fastavro.schema import load_schema\n",
    "from fastavro import writer, reader, parse_schema\n",
    "#import pygeohashpisr d\n",
    "import pygeohash\n",
    "import snappy\n",
    "import jsonschema\n",
    "from jsonschema import validate\n",
    "\n",
    "from jsonschema.exceptions import ValidationError\n",
    "\n",
    "\n",
    "endpoint_url='/home/jovyan/'\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "schema_dir = current_dir.joinpath('schemas')\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(current_dir)\n",
    "print(schema_dir)\n",
    "print(results_dir)\n",
    "\n",
    "def read_jsonl_data():\n",
    "    f_gz = '/home/jovyan/assignment03_Vayuvegula_SomaShekar/data/processed/openflights/routes.jsonl.gz'\n",
    "    with gzip.open(f_gz, 'rb') as f:\n",
    "        records = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the records from https://storage.budsc.midwest-datascience.com/data/processed/openflights/routes.jsonl.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = read_jsonl_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.a JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate_jsonl_data(records):\n",
    "    schema_path = schema_dir.joinpath('routes-schema.json')\n",
    "    with open(schema_path) as f:\n",
    "        schema = json.load(f)\n",
    "    validation_csv_path = results_dir.joinpath('validation-results.csv')\n",
    "    # Open the validation CSV\n",
    "    with open(validation_csv_path, 'w', encoding=\"utf-8\") as f:\n",
    "        # Create column names\n",
    "        fieldnames = ['row', 'valid', 'msg']\n",
    "        # Assign CSV writer object\n",
    "        csv_writer = csv.DictWriter(f, fieldnames=fieldnames, lineterminator = '\\n')\n",
    "        csv_writer.writeheader()   \n",
    "        for i, record in enumerate(records):\n",
    "            try:\n",
    "                ## TODO: Validate record \n",
    "                result = dict(\n",
    "                    row = i,\n",
    "                    valid = True,\n",
    "                    msg = record\n",
    "                )\n",
    "                pass\n",
    "            except ValidationError as e:\n",
    "                ## Print message if invalid record\n",
    "                result = dict(\n",
    "                    row = i,\n",
    "                    valid = False,\n",
    "                    msg = record\n",
    "                )\n",
    "                pass\n",
    "            finally:\n",
    "                # Write the line to the CSV.\n",
    "                csv_writer.writerow(result)\n",
    "\n",
    "validate_jsonl_data(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.b Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avro_dataset(records):\n",
    "    schema_path = schema_dir.joinpath('routes.avsc')\n",
    "    data_path = results_dir.joinpath('routes.avro')\n",
    "    ## TODO: Use fastavro to create Avro dataset\n",
    "    with open(schema_path) as f:\n",
    "        schema = json.load(f)  \n",
    "    with open(data_path, 'wb') as out:\n",
    "        fastavro.writer(out, schema, records)\n",
    "        \n",
    "create_avro_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.c Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "airline: struct<active: bool, airline_id: int64, alias: string, callsign: string, country: string, iata: string, icao: string, name: string>\n",
      "  child 0, active: bool\n",
      "  child 1, airline_id: int64\n",
      "  child 2, alias: string\n",
      "  child 3, callsign: string\n",
      "  child 4, country: string\n",
      "  child 5, iata: string\n",
      "  child 6, icao: string\n",
      "  child 7, name: string\n",
      "src_airport: struct<airport_id: int64, altitude: int64, city: string, country: string, dst: string, iata: string, icao: string, latitude: double, longitude: double, name: string, source: string, timezone: double, type: string, tz_id: string>\n",
      "  child 0, airport_id: int64\n",
      "  child 1, altitude: int64\n",
      "  child 2, city: string\n",
      "  child 3, country: string\n",
      "  child 4, dst: string\n",
      "  child 5, iata: string\n",
      "  child 6, icao: string\n",
      "  child 7, latitude: double\n",
      "  child 8, longitude: double\n",
      "  child 9, name: string\n",
      "  child 10, source: string\n",
      "  child 11, timezone: double\n",
      "  child 12, type: string\n",
      "  child 13, tz_id: string\n",
      "dst_airport: struct<airport_id: int64, altitude: int64, city: string, country: string, dst: string, iata: string, icao: string, latitude: double, longitude: double, name: string, source: string, timezone: double, type: string, tz_id: string>\n",
      "  child 0, airport_id: int64\n",
      "  child 1, altitude: int64\n",
      "  child 2, city: string\n",
      "  child 3, country: string\n",
      "  child 4, dst: string\n",
      "  child 5, iata: string\n",
      "  child 6, icao: string\n",
      "  child 7, latitude: double\n",
      "  child 8, longitude: double\n",
      "  child 9, name: string\n",
      "  child 10, source: string\n",
      "  child 11, timezone: double\n",
      "  child 12, type: string\n",
      "  child 13, tz_id: string\n",
      "codeshare: bool\n",
      "equipment: list<item: string>\n",
      "  child 0, item: string\n",
      "----\n",
      "airline: [\n",
      "  -- is_valid: all not null\n",
      "  -- child 0 type: bool\n",
      "[true,true,true,true,true,...,true,true,true,true,true]\n",
      "  -- child 1 type: int64\n",
      "[410,410,410,410,410,...,4178,19016,19016,19016,19016]\n",
      "  -- child 2 type: string\n",
      "[\"ANA All Nippon Airways\",\"ANA All Nippon Airways\",\"ANA All Nippon Airways\",\"ANA All Nippon Airways\",\"ANA All Nippon Airways\",...,\"Qantas Airways\",\"Apache\",\"Apache\",\"Apache\",\"Apache\"]\n",
      "  -- child 3 type: string\n",
      "[\"AEROCONDOR\",\"AEROCONDOR\",\"AEROCONDOR\",\"AEROCONDOR\",\"AEROCONDOR\",...,\"REX\",\"APACHE\",\"APACHE\",\"APACHE\",\"APACHE\"]\n",
      "  -- child 4 type: string\n",
      "[\"Portugal\",\"Portugal\",\"Portugal\",\"Portugal\",\"Portugal\",...,\"Australia\",\"United States\",\"United States\",\"United States\",\"United States\"]\n",
      "  -- child 5 type: string\n",
      "[\"2B\",\"2B\",\"2B\",\"2B\",\"2B\",...,\"ZL\",\"ZM\",\"ZM\",\"ZM\",\"ZM\"]\n",
      "  -- child 6 type: string\n",
      "[\"ARD\",\"ARD\",\"ARD\",\"ARD\",\"ARD\",...,\"RXA\",\"IWA\",\"IWA\",\"IWA\",\"IWA\"]\n",
      "  -- child 7 type: string\n",
      "[\"Aerocondor\",\"Aerocondor\",\"Aerocondor\",\"Aerocondor\",\"Aerocondor\",...,\"Regional Express\",\"Apache Air\",\"Apache Air\",\"Apache Air\",\"Apache Air\"]]\n",
      "src_airport: [\n",
      "  -- is_valid:  [true,true,true,true,true,...,true,true,true,true,true]\n",
      "  -- child 0 type: int64\n",
      "[2965,2966,2966,2968,2968,...,6334,4029,2912,2912,2913]\n",
      "  -- child 1 type: int64\n",
      "[89,-65,-65,769,769,...,41,588,2058,2058,2927]\n",
      "  -- child 2 type: string\n",
      "[\"Sochi\",\"Astrakhan\",\"Astrakhan\",\"Chelyabinsk\",\"Chelyabinsk\",...,\"Whyalla\",\"Moscow\",\"Bishkek\",\"Bishkek\",\"Osh\"]\n",
      "  -- child 3 type: string\n",
      "[\"Russia\",\"Russia\",\"Russia\",\"Russia\",\"Russia\",...,\"Australia\",\"Russia\",\"Kyrgyzstan\",\"Kyrgyzstan\",\"Kyrgyzstan\"]\n",
      "  -- child 4 type: string\n",
      "[\"N\",\"N\",\"N\",\"N\",\"N\",...,\"O\",\"N\",\"U\",\"U\",\"U\"]\n",
      "  -- child 5 type: string\n",
      "[\"AER\",\"ASF\",\"ASF\",\"CEK\",\"CEK\",...,\"WYA\",\"DME\",\"FRU\",\"FRU\",\"OSS\"]\n",
      "  -- child 6 type: string\n",
      "[\"URSS\",\"URWA\",\"URWA\",\"USCC\",\"USCC\",...,\"YWHA\",\"UUDD\",\"UAFM\",\"UAFM\",\"UAFO\"]\n",
      "  -- child 7 type: double\n",
      "[43.449902,46.2832984924,46.2832984924,55.305801,55.305801,...,-33.05889892578125,55.40879821777344,43.0612983704,43.0612983704,40.6090011597]\n",
      "  -- child 8 type: double\n",
      "[39.9566,48.0063018799,48.0063018799,61.5033,61.5033,...,137.51400756835938,37.90629959106445,74.4776000977,74.4776000977,72.793296814]\n",
      "  -- child 9 type: string\n",
      "[\"Sochi International Airport\",\"Astrakhan Airport\",\"Astrakhan Airport\",\"Chelyabinsk Balandino Airport\",\"Chelyabinsk Balandino Airport\",...,\"Whyalla Airport\",\"Domodedovo International Airport\",\"Manas International Airport\",\"Manas International Airport\",\"Osh Airport\"]\n",
      "  -- child 10 type: string\n",
      "[\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\",...,\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\"]\n",
      "  -- child 11 type: double\n",
      "[3,4,4,5,5,...,9.5,3,6,6,6]\n",
      "  -- child 12 type: string\n",
      "[\"airport\",\"airport\",\"airport\",\"airport\",\"airport\",...,\"airport\",\"airport\",\"airport\",\"airport\",\"airport\"]\n",
      "  -- child 13 type: string\n",
      "[\"Europe/Moscow\",\"Europe/Samara\",\"Europe/Samara\",\"Asia/Yekaterinburg\",\"Asia/Yekaterinburg\",...,\"Australia/Adelaide\",\"Europe/Moscow\",\"Asia/Bishkek\",\"Asia/Bishkek\",\"Asia/Bishkek\"]]\n",
      "dst_airport: [\n",
      "  -- is_valid:  [true,true,true,true,true,...,true,true,true,true,true]\n",
      "  -- child 0 type: int64\n",
      "[2990,2990,2962,2990,4078,...,3341,2912,4029,2913,2912]\n",
      "  -- child 1 type: int64\n",
      "[411,411,1054,411,365,...,20,2058,588,2927,2058]\n",
      "  -- child 2 type: string\n",
      "[\"Kazan\",\"Kazan\",\"Mineralnye Vody\",\"Kazan\",\"Novosibirsk\",...,\"Adelaide\",\"Bishkek\",\"Moscow\",\"Osh\",\"Bishkek\"]\n",
      "  -- child 3 type: string\n",
      "[\"Russia\",\"Russia\",\"Russia\",\"Russia\",\"Russia\",...,\"Australia\",\"Kyrgyzstan\",\"Russia\",\"Kyrgyzstan\",\"Kyrgyzstan\"]\n",
      "  -- child 4 type: string\n",
      "[\"N\",\"N\",\"N\",\"N\",\"N\",...,\"O\",\"U\",\"N\",\"U\",\"U\"]\n",
      "  -- child 5 type: string\n",
      "[\"KZN\",\"KZN\",\"MRV\",\"KZN\",\"OVB\",...,\"ADL\",\"FRU\",\"DME\",\"OSS\",\"FRU\"]\n",
      "  -- child 6 type: string\n",
      "[\"UWKD\",\"UWKD\",\"URMM\",\"UWKD\",\"UNNT\",...,\"YPAD\",\"UAFM\",\"UUDD\",\"UAFO\",\"UAFM\"]\n",
      "  -- child 7 type: double\n",
      "[55.606201171875,55.606201171875,44.22510147094727,55.606201171875,55.012599945068,...,-34.945,43.0612983704,55.40879821777344,40.6090011597,43.0612983704]\n",
      "  -- child 8 type: double\n",
      "[49.278701782227,49.278701782227,43.08190155029297,49.278701782227,82.650703430176,...,138.53100600000002,74.4776000977,37.90629959106445,72.793296814,74.4776000977]\n",
      "  -- child 9 type: string\n",
      "[\"Kazan International Airport\",\"Kazan International Airport\",\"Mineralnyye Vody Airport\",\"Kazan International Airport\",\"Tolmachevo Airport\",...,\"Adelaide International Airport\",\"Manas International Airport\",\"Domodedovo International Airport\",\"Osh Airport\",\"Manas International Airport\"]\n",
      "  -- child 10 type: string\n",
      "[\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\",...,\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\",\"OurAirports\"]\n",
      "  -- child 11 type: double\n",
      "[3,3,3,3,7,...,9.5,6,3,6,6]\n",
      "  -- child 12 type: string\n",
      "[\"airport\",\"airport\",\"airport\",\"airport\",\"airport\",...,\"airport\",\"airport\",\"airport\",\"airport\",\"airport\"]\n",
      "  -- child 13 type: string\n",
      "[\"Europe/Moscow\",\"Europe/Moscow\",\"Europe/Moscow\",\"Europe/Moscow\",\"Asia/Krasnoyarsk\",...,\"Australia/Adelaide\",\"Asia/Bishkek\",\"Europe/Moscow\",\"Asia/Bishkek\",\"Asia/Bishkek\"]]\n",
      "codeshare: [[false,false,false,false,false,...,false,false,false,false,false]]\n",
      "equipment: [[[\"CR2\"],[\"CR2\"],...,[\"734\"],[\"734\"]]]\n"
     ]
    }
   ],
   "source": [
    "def create_parquet_dataset():\n",
    "    src_data_path = '/home/jovyan/assignment03_Vayuvegula_SomaShekar/data/processed/openflights/routes.jsonl.gz'\n",
    "    parquet_output_path = results_dir.joinpath('routes.parquet')\n",
    "    \"\"\" \n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    with gzip.open(src_data_path, 'rb') as f:\n",
    "        records = [json.loads(line) for line in f.readlines()]\n",
    "    print(records)\n",
    "    df = pd.DataFrame(records)\n",
    "    ## TODO: Use Apache Arrow to create Parquet table and save the dataset\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    print(table)\n",
    "    pq.write_table(table, parquet_output_path, compression='none')\n",
    "\n",
    "create_parquet_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.d Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('routes_pb2'))\n",
    "\n",
    "import routes_pb2\n",
    "\n",
    "def _airport_to_proto_obj(airport):\n",
    "    obj = routes_pb2.Airport()\n",
    "    if airport is None:\n",
    "        return None\n",
    "    if airport.get('airport_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airport_id = airport.get('airport_id')\n",
    "    if airport.get('name'):\n",
    "        obj.name = airport.get('name')\n",
    "    if airport.get('city'):\n",
    "        obj.city = airport.get('city')\n",
    "    if airport.get('iata'):\n",
    "        obj.iata = airport.get('iata')\n",
    "    if airport.get('icao'):\n",
    "        obj.icao = airport.get('icao')\n",
    "    if airport.get('altitude'):\n",
    "        obj.altitude = airport.get('altitude')\n",
    "    if airport.get('timezone'):\n",
    "        obj.timezone = airport.get('timezone')\n",
    "    if airport.get('dst'):\n",
    "        obj.dst = airport.get('dst')\n",
    "    if airport.get('tz_id'):\n",
    "        obj.tz_id = airport.get('tz_id')\n",
    "    if airport.get('type'):\n",
    "        obj.type = airport.get('type')\n",
    "    if airport.get('source'):\n",
    "        obj.source = airport.get('source')\n",
    "\n",
    "    obj.latitude = airport.get('latitude')\n",
    "    obj.longitude = airport.get('longitude')\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "def _airline_to_proto_obj(airline):\n",
    "    obj = routes_pb2.Airline()\n",
    "    ## TODO: Create an Airline obj using Protocol Buffers API\n",
    "    if airline is None:\n",
    "        return None\n",
    "    if airline.get('airline_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airline_id = airline.get('airline_id')\n",
    "    if airline.get('name'):\n",
    "        obj.name = airline.get('name')\n",
    "    if airline.get('alias'):\n",
    "        obj.alias = airline.get('alias')\n",
    "    if airline.get('iata'):\n",
    "        obj.iata = airline.get('iata')\n",
    "    if airline.get('icao'):\n",
    "        obj.icao = airline.get('icao')\n",
    "    if airline.get('callsign'):\n",
    "        obj.callsign = airline.get('callsign')\n",
    "    if airline.get('country'):\n",
    "        obj.country = airline.get('country')\n",
    "    if airline.get('active'):\n",
    "        obj.active = airline.get('active')\n",
    "        \n",
    "    return obj\n",
    "\n",
    "\n",
    "def create_protobuf_dataset(records):\n",
    "    routes = routes_pb2.Routes()\n",
    "    for record in records:\n",
    "        route = routes_pb2.Route()\n",
    "        ## TODO: Implement the code to create the Protocol Buffers Dataset\n",
    "        for key, value in record.items():\n",
    "            if key=='airline':\n",
    "                airline = _airline_to_proto_obj(value)\n",
    "                airin = route.airline\n",
    "                airin.name = airline.name\n",
    "                airin.airline_id = airline.airline_id\n",
    "                airin.active = airline.active\n",
    "            if key=='src_airport' and value is not None:\n",
    "                src_airport = _airport_to_proto_obj(value)\n",
    "                srcairin = route.src_airport\n",
    "                srcairin.name = src_airport.name\n",
    "                srcairin.airport_id = src_airport.airport_id\n",
    "                srcairin.latitude = src_airport.latitude\n",
    "                srcairin.longitude = src_airport.longitude\n",
    "\n",
    "            if key=='dst_airport' and value is not None:\n",
    "                dst_airport = _airport_to_proto_obj(value)\n",
    "                dstairin = route.dst_airport\n",
    "                dstairin.name = dst_airport.name\n",
    "                dstairin.airport_id = dst_airport.airport_id\n",
    "                dstairin.latitude = dst_airport.latitude\n",
    "                dstairin.longitude = dst_airport.longitude\n",
    "\n",
    "            if key=='codeshare':\n",
    "                route.codeshare = value\n",
    "\n",
    "        routes.route.append(route)\n",
    "\n",
    "    data_path = results_dir.joinpath('routes.pb')\n",
    "\n",
    "    with open(data_path, 'wb') as f:\n",
    "        f.write(routes.SerializeToString())\n",
    "        \n",
    "    compressed_path = results_dir.joinpath('routes.pb.snappy')\n",
    "    \n",
    "    with open(compressed_path, 'wb') as f:\n",
    "        f.write(snappy.compress(routes.SerializeToString()))\n",
    "        \n",
    "create_protobuf_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.a Simple Geohash Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latitude = src_airport.get('latitude')\n",
    "            longitude = src_airport.get('longitude')\n",
    "            if latitude and longitude:\n",
    "                ## TODO: use pygeohash.encode() to assign geohashes to the records and complete the hashes list\n",
    "                hashes.append(pygeohash.encode(longitude=longitude,latitude=latitude,precision=3))\n",
    "                record['geohash'] = pygeohash.encode(longitude=longitude,latitude=latitude,precision=3)\n",
    "    hashes.sort()\n",
    "    three_letter = sorted(list(set([entry[:3] for entry in hashes])))\n",
    "    hash_index = {value: [] for value in three_letter}\n",
    "    for record in records:\n",
    "        geohash = record.get('geohash')\n",
    "        if geohash:\n",
    "            hash_index[geohash[:3]].append(record)\n",
    "    for key, values in hash_index.items():\n",
    "        output_dir = geoindex_dir.joinpath(str(key[:1])).joinpath(str(key[:2]))\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        output_path = output_dir.joinpath('{}.jsonl.gz'.format(key))\n",
    "        with gzip.open(output_path, 'w') as f:\n",
    "            json_output = '\\n'.join([json.dumps(value) for value in values])\n",
    "            f.write(json_output.encode('utf-8'))\n",
    "            \n",
    "create_hash_dirs(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.b Simple Search Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest airport is:Southwest Airlines, which is: 19545 km away\n"
     ]
    }
   ],
   "source": [
    "def airport_search(latitude, longitude):\n",
    "    src_geohash_code = pygeohash.encode(longitude=longitude,latitude=latitude,precision=15)\n",
    "    # load the data from that file\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    # building my search area\n",
    "    my_geo_dir = geoindex_dir.joinpath(str(src_geohash_code[0]))\n",
    "    my_geo_dir = my_geo_dir.joinpath(str(src_geohash_code[:2]))\n",
    "    my_geo_dir = my_geo_dir.joinpath(str(src_geohash_code[:3])+\".jsonl.gz\")\n",
    "\n",
    "    # print(my_geo_dir)\n",
    "    with open(my_geo_dir, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            geo_records = [json.loads(line) for line in f.readlines()]\n",
    "            current_dis = 0\n",
    "            closest_airport = {}\n",
    "            for distance in geo_records:\n",
    "                if distance['src_airport']:\n",
    "                    temp_lat = distance[\"src_airport\"][\"latitude\"]\n",
    "                    temp_lon = distance[\"src_airport\"][\"longitude\"]\n",
    "                    dst_geohash_code = pygeohash.encode(longitude=temp_lon,latitude=temp_lat,precision=15)\n",
    "                    dis = pygeohash.geohash_approximate_distance(str(src_geohash_code), str(dst_geohash_code))\n",
    "                    if current_dis == 0 or dis <= current_dis:\n",
    "                        current_dis = dis\n",
    "                        closest_airport = distance[\"airline\"][\"name\"]\n",
    "\n",
    "            print(\"The closest airport is:\" + closest_airport + \", which is: \"+ str(current_dis) + \" km away\")\n",
    "\n",
    "airport_search(41.1499988, -95.91779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
